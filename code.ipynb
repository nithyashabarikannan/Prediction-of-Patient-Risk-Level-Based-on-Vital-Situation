{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of Patient Risk Level Based on Vital Situation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the number of medical cases increasing these days, Doctors and scientists alike have turned to machine learning (ML) techniques to develop screening tools and this is because of their superiority in pattern recognition and classification as compared to other traditional statistical approaches.\n",
    "\n",
    "There is much difficulty in identifying high risk patients because of the multi-factorial nature of several contributory risk factors such as diabetes, high blood pressure, high cholesterol et cetera. Due to such constraints, scientists have turned towards modern approaches like Data Mining and Machine Learning for predicting the disease.\n",
    "\n",
    "This prediction helps in identifying if a patient’s health risk is based on his/her medical recordings such as blood pressure levels, pulse rate, oxygen levels and more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset:\n",
    "The data set provides the patients’ information which includes over 12,00,000+ records and 7+ attributes. Each attribute is a potential risk factor and they include various Information on current medical condition centred date wise.\n",
    "\n",
    "• blood_pressure_average\n",
    "\n",
    "• blood_pressure_systolic\n",
    "\n",
    "• blood_pressure_diastolic\n",
    "\n",
    "• heart_rate\n",
    "\n",
    "• respiration_over_impedence\n",
    "\n",
    "• spirometry_oxygen_saturation\n",
    "\n",
    "• pulse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models:\n",
    "<b>K-nearest neighbor</b>-predict the features of a data point based on the features of its neighbors\n",
    "\n",
    "<b>Naive Bayes Classifie</b>-a collection of classification algorithms based on Bayes' Theorem\n",
    "\n",
    "<b>Decision Tree</b>-creates a decision tree based on which, it assigns the class values to each data point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language:\n",
    "This prediction is implemented in <b>Python</b> and different its classification algorithms. Python is a high-level, object-oriented programming language with dynamic building options and fast development cycles. However, many may not know that it's also one of the safest programming languages with useful applications in healthcare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target variable to predict:\n",
    "The <b>“Coded”</b> indicates the actual result whether the patient is at risk or not. This variable can hold binary values “1” and “2” where binary: “1”, means “There is a risk” and “0” means “There is no risk”. This is the value to be predicted by the machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries\n",
    "Python code in one module gains access to the code in another module by the process of importing it. Let's include some basic libaries first.\n",
    "\n",
    "• <b>Pandas</b>-data manipulation and analysis\n",
    "\n",
    "• <b>Numpy</b>- working with arrays\n",
    "\n",
    "• <b>Seaborn</b>- data visualization library based on matplotlib\n",
    "\n",
    "• <b>Matplotlib</b>- 2D plots of arrays\n",
    "\n",
    "• <b>sklearn.neighbors</b>- Classifier implementing the k-nearest neighbors vote\n",
    "\n",
    "• <b>sklearn.tree- Classifier</b> implementing the Desicion tree model\n",
    "\n",
    "• <b>sklearn.ensemble</b>-averaging algorithms based on randomized decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sbn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset\n",
    "Now that we have all the libraries we will need, we can import the dataset and take a look at it. The dataset is stored in the <b>training_frame.csv</b> file for training the models and <b>test_frame.csv</b> for testing the algorithms I'll use the pandas read_csv method to read the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pd.read_csv(\"training_frame.csv\")\n",
    "testing_df = pd.read_csv(\"test_frame.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 13 columns):\n",
      " #   Column                        Non-Null Count   Dtype \n",
      "---  ------                        --------------   ----- \n",
      " 0   sn                            100000 non-null  int64 \n",
      " 1   date                          100000 non-null  object\n",
      " 2   time                          100000 non-null  object\n",
      " 3   heart_rate                    100000 non-null  int64 \n",
      " 4   respiration_over_impedence    100000 non-null  int64 \n",
      " 5   spirometry_oxygen_saturation  100000 non-null  int64 \n",
      " 6   pulse                         100000 non-null  int64 \n",
      " 7   blood_pressure_systolic       100000 non-null  int64 \n",
      " 8   blood_pressure_diastolic      100000 non-null  int64 \n",
      " 9   blood_pressure_average        100000 non-null  int64 \n",
      " 10  patient_id                    100000 non-null  int64 \n",
      " 11  machine_id                    100000 non-null  object\n",
      " 12  Coded                         100000 non-null  int64 \n",
      "dtypes: int64(10), object(3)\n",
      "memory usage: 8.8+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 13 columns):\n",
      " #   Column                        Non-Null Count   Dtype \n",
      "---  ------                        --------------   ----- \n",
      " 0   Unnamed: 0                    100000 non-null  int64 \n",
      " 1   date                          100000 non-null  object\n",
      " 2   time                          100000 non-null  object\n",
      " 3   heart_rate                    100000 non-null  int64 \n",
      " 4   respiration_over_impedence    100000 non-null  int64 \n",
      " 5   spirometry_oxygen_saturation  100000 non-null  int64 \n",
      " 6   pulse                         100000 non-null  int64 \n",
      " 7   blood_pressure_systolic       100000 non-null  int64 \n",
      " 8   blood_pressure_diastolic      100000 non-null  int64 \n",
      " 9   blood_pressure_average        100000 non-null  int64 \n",
      " 10  patient_id                    100000 non-null  int64 \n",
      " 11  machine_id                    100000 non-null  object\n",
      " 12  Coded                         100000 non-null  int64 \n",
      "dtypes: int64(10), object(3)\n",
      "memory usage: 8.8+ MB\n"
     ]
    }
   ],
   "source": [
    "training_df.info()\n",
    "testing_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since ID cannot be used for classification we can drop the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_df.drop('sn',axis=1,inplace=True)\n",
    "training_df.drop('time',axis=1,inplace=True)\n",
    "training_df.drop('machine_id',axis=1,inplace=True)\n",
    "testing_df.drop('machine_id',axis=1,inplace=True)\n",
    "testing_df.drop('time',axis=1,inplace=True)\n",
    "testing_df.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 11 columns):\n",
      " #   Column                        Non-Null Count   Dtype         \n",
      "---  ------                        --------------   -----         \n",
      " 0   date                          100000 non-null  datetime64[ns]\n",
      " 1   heart_rate                    100000 non-null  int64         \n",
      " 2   respiration_over_impedence    100000 non-null  int64         \n",
      " 3   spirometry_oxygen_saturation  100000 non-null  int64         \n",
      " 4   pulse                         100000 non-null  int64         \n",
      " 5   blood_pressure_systolic       100000 non-null  int64         \n",
      " 6   blood_pressure_diastolic      100000 non-null  int64         \n",
      " 7   blood_pressure_average        100000 non-null  int64         \n",
      " 8   patient_id                    100000 non-null  int64         \n",
      " 9   Coded                         100000 non-null  int64         \n",
      " 10  new_date                      100000 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](2), int64(9)\n",
      "memory usage: 8.4 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 11 columns):\n",
      " #   Column                        Non-Null Count   Dtype         \n",
      "---  ------                        --------------   -----         \n",
      " 0   date                          100000 non-null  datetime64[ns]\n",
      " 1   heart_rate                    100000 non-null  int64         \n",
      " 2   respiration_over_impedence    100000 non-null  int64         \n",
      " 3   spirometry_oxygen_saturation  100000 non-null  int64         \n",
      " 4   pulse                         100000 non-null  int64         \n",
      " 5   blood_pressure_systolic       100000 non-null  int64         \n",
      " 6   blood_pressure_diastolic      100000 non-null  int64         \n",
      " 7   blood_pressure_average        100000 non-null  int64         \n",
      " 8   patient_id                    100000 non-null  int64         \n",
      " 9   Coded                         100000 non-null  int64         \n",
      " 10  new_date                      100000 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](2), int64(9)\n",
      "memory usage: 8.4 MB\n"
     ]
    }
   ],
   "source": [
    "training_df['new_date'] = pd.to_datetime(training_df['date'], format='%d-%M-%Y')\n",
    "testing_df['new_date'] = pd.to_datetime(testing_df['date'], format='%d-%M-%Y')\n",
    "training_df['date'] = training_df['new_date']\n",
    "testing_df['date'] = testing_df['new_date']\n",
    "training_df.info()\n",
    "testing_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we cannot use date data for classification, we will convert it into an ordinal value for classification purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import datetime as dt\n",
    "training_df['date_ord']=training_df['date'].map(dt.datetime.toordinal)\n",
    "testing_df['date_ord']=testing_df['date'].map(dt.datetime.toordinal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now Check for any null values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                            False\n",
       "heart_rate                      False\n",
       "respiration_over_impedence      False\n",
       "spirometry_oxygen_saturation    False\n",
       "pulse                           False\n",
       "blood_pressure_systolic         False\n",
       "blood_pressure_diastolic        False\n",
       "blood_pressure_average          False\n",
       "patient_id                      False\n",
       "Coded                           False\n",
       "new_date                        False\n",
       "date_ord                        False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "training_df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                            False\n",
       "heart_rate                      False\n",
       "respiration_over_impedence      False\n",
       "spirometry_oxygen_saturation    False\n",
       "pulse                           False\n",
       "blood_pressure_systolic         False\n",
       "blood_pressure_diastolic        False\n",
       "blood_pressure_average          False\n",
       "patient_id                      False\n",
       "Coded                           False\n",
       "new_date                        False\n",
       "date_ord                        False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>respiration_over_impedence</th>\n",
       "      <th>spirometry_oxygen_saturation</th>\n",
       "      <th>pulse</th>\n",
       "      <th>blood_pressure_systolic</th>\n",
       "      <th>blood_pressure_diastolic</th>\n",
       "      <th>blood_pressure_average</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>Coded</th>\n",
       "      <th>date_ord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.0000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>1.000000e+05</td>\n",
       "      <td>100000.00000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94.145950</td>\n",
       "      <td>20.613890</td>\n",
       "      <td>96.7810</td>\n",
       "      <td>91.112420</td>\n",
       "      <td>128.516980</td>\n",
       "      <td>73.670880</td>\n",
       "      <td>90.769060</td>\n",
       "      <td>1.291026e+06</td>\n",
       "      <td>0.30000</td>\n",
       "      <td>737445.443840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>24.649687</td>\n",
       "      <td>35.864277</td>\n",
       "      <td>4.5127</td>\n",
       "      <td>19.871738</td>\n",
       "      <td>25.759159</td>\n",
       "      <td>16.166517</td>\n",
       "      <td>19.286323</td>\n",
       "      <td>5.419573e+05</td>\n",
       "      <td>0.45826</td>\n",
       "      <td>5.263852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7499.000000</td>\n",
       "      <td>12.0000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.679400e+04</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>737425.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>75.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>96.0000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.140714e+06</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>737443.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>92.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>98.0000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>1.353516e+06</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>737446.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>108.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>1.816965e+06</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>737449.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>233.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>261.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>9.038929e+06</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>737455.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          heart_rate  respiration_over_impedence  \\\n",
       "count  100000.000000               100000.000000   \n",
       "mean       94.145950                   20.613890   \n",
       "std        24.649687                   35.864277   \n",
       "min         0.000000                -7499.000000   \n",
       "25%        75.000000                   15.000000   \n",
       "50%        92.000000                   20.000000   \n",
       "75%       108.000000                   25.000000   \n",
       "max       233.000000                  150.000000   \n",
       "\n",
       "       spirometry_oxygen_saturation          pulse  blood_pressure_systolic  \\\n",
       "count                   100000.0000  100000.000000            100000.000000   \n",
       "mean                        96.7810      91.112420               128.516980   \n",
       "std                          4.5127      19.871738                25.759159   \n",
       "min                         12.0000      33.000000                29.000000   \n",
       "25%                         96.0000      75.000000               109.000000   \n",
       "50%                         98.0000      91.000000               129.000000   \n",
       "75%                        100.0000     104.000000               147.000000   \n",
       "max                        100.0000     292.000000               261.000000   \n",
       "\n",
       "       blood_pressure_diastolic  blood_pressure_average    patient_id  \\\n",
       "count             100000.000000           100000.000000  1.000000e+05   \n",
       "mean                  73.670880               90.769060  1.291026e+06   \n",
       "std                   16.166517               19.286323  5.419573e+05   \n",
       "min                   13.000000               15.000000  1.679400e+04   \n",
       "25%                   62.000000               77.000000  1.140714e+06   \n",
       "50%                   73.000000               89.000000  1.353516e+06   \n",
       "75%                   83.000000              103.000000  1.816965e+06   \n",
       "max                  267.000000              279.000000  9.038929e+06   \n",
       "\n",
       "              Coded       date_ord  \n",
       "count  100000.00000  100000.000000  \n",
       "mean        0.30000  737445.443840  \n",
       "std         0.45826       5.263852  \n",
       "min         0.00000  737425.000000  \n",
       "25%         0.00000  737443.000000  \n",
       "50%         0.00000  737446.000000  \n",
       "75%         1.00000  737449.000000  \n",
       "max         1.00000  737455.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now lets also split the data into our features and labels, then map our labels to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Coded', ylabel='count'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "sbn.countplot(x = 'Coded', data = training_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Aggregate</b> testing data by patient id and date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tdf = testing_df.groupby(['patient_id','date_ord'], as_index = False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>date_ord</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>respiration_over_impedence</th>\n",
       "      <th>spirometry_oxygen_saturation</th>\n",
       "      <th>pulse</th>\n",
       "      <th>blood_pressure_systolic</th>\n",
       "      <th>blood_pressure_diastolic</th>\n",
       "      <th>blood_pressure_average</th>\n",
       "      <th>Coded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20145</td>\n",
       "      <td>737428</td>\n",
       "      <td>85.142857</td>\n",
       "      <td>22.357143</td>\n",
       "      <td>95.091837</td>\n",
       "      <td>84.887755</td>\n",
       "      <td>115.336735</td>\n",
       "      <td>63.806122</td>\n",
       "      <td>83.959184</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20145</td>\n",
       "      <td>737429</td>\n",
       "      <td>86.446809</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>96.537234</td>\n",
       "      <td>83.872340</td>\n",
       "      <td>114.962766</td>\n",
       "      <td>63.856383</td>\n",
       "      <td>83.925532</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27624</td>\n",
       "      <td>737427</td>\n",
       "      <td>56.237918</td>\n",
       "      <td>16.241636</td>\n",
       "      <td>99.732342</td>\n",
       "      <td>59.085502</td>\n",
       "      <td>158.795539</td>\n",
       "      <td>89.438662</td>\n",
       "      <td>111.204461</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27624</td>\n",
       "      <td>737428</td>\n",
       "      <td>65.853333</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>99.792000</td>\n",
       "      <td>65.706667</td>\n",
       "      <td>159.642667</td>\n",
       "      <td>89.786667</td>\n",
       "      <td>111.085333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27624</td>\n",
       "      <td>737429</td>\n",
       "      <td>59.052632</td>\n",
       "      <td>13.033241</td>\n",
       "      <td>99.822715</td>\n",
       "      <td>59.116343</td>\n",
       "      <td>159.775623</td>\n",
       "      <td>89.858726</td>\n",
       "      <td>111.590028</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id  date_ord  heart_rate  respiration_over_impedence  \\\n",
       "0       20145    737428   85.142857                   22.357143   \n",
       "1       20145    737429   86.446809                   25.500000   \n",
       "2       27624    737427   56.237918                   16.241636   \n",
       "3       27624    737428   65.853333                   14.280000   \n",
       "4       27624    737429   59.052632                   13.033241   \n",
       "\n",
       "   spirometry_oxygen_saturation      pulse  blood_pressure_systolic  \\\n",
       "0                     95.091837  84.887755               115.336735   \n",
       "1                     96.537234  83.872340               114.962766   \n",
       "2                     99.732342  59.085502               158.795539   \n",
       "3                     99.792000  65.706667               159.642667   \n",
       "4                     99.822715  59.116343               159.775623   \n",
       "\n",
       "   blood_pressure_diastolic  blood_pressure_average  Coded  \n",
       "0                 63.806122               83.959184    0.0  \n",
       "1                 63.856383               83.925532    0.0  \n",
       "2                 89.438662              111.204461    0.0  \n",
       "3                 89.786667              111.085333    0.0  \n",
       "4                 89.858726              111.590028    0.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building\n",
    "In this step we will divide the data into test and train data to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 10 columns):\n",
      " #   Column                        Non-Null Count   Dtype\n",
      "---  ------                        --------------   -----\n",
      " 0   patient_id                    100000 non-null  int64\n",
      " 1   date_ord                      100000 non-null  int64\n",
      " 2   heart_rate                    100000 non-null  int64\n",
      " 3   respiration_over_impedence    100000 non-null  int64\n",
      " 4   spirometry_oxygen_saturation  100000 non-null  int64\n",
      " 5   pulse                         100000 non-null  int64\n",
      " 6   blood_pressure_systolic       100000 non-null  int64\n",
      " 7   blood_pressure_diastolic      100000 non-null  int64\n",
      " 8   blood_pressure_average        100000 non-null  int64\n",
      " 9   Coded                         100000 non-null  int64\n",
      "dtypes: int64(10)\n",
      "memory usage: 7.6 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 351 entries, 0 to 350\n",
      "Data columns (total 10 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   patient_id                    351 non-null    int64  \n",
      " 1   date_ord                      351 non-null    int64  \n",
      " 2   heart_rate                    351 non-null    float64\n",
      " 3   respiration_over_impedence    351 non-null    float64\n",
      " 4   spirometry_oxygen_saturation  351 non-null    float64\n",
      " 5   pulse                         351 non-null    float64\n",
      " 6   blood_pressure_systolic       351 non-null    float64\n",
      " 7   blood_pressure_diastolic      351 non-null    float64\n",
      " 8   blood_pressure_average        351 non-null    float64\n",
      " 9   Coded                         351 non-null    float64\n",
      "dtypes: float64(8), int64(2)\n",
      "memory usage: 30.2 KB\n"
     ]
    }
   ],
   "source": [
    "#training_df.info()\n",
    "trdf = training_df\n",
    "trdf = trdf.drop('date', axis = 1)\n",
    "trdf = trdf.drop('new_date', axis = 1)\n",
    "trdf = trdf[['patient_id','date_ord','heart_rate','respiration_over_impedence','spirometry_oxygen_saturation','pulse','blood_pressure_systolic'\n",
    "            ,'blood_pressure_diastolic','blood_pressure_average','Coded']]\n",
    "trdf.info()\n",
    "tdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 9 columns):\n",
      " #   Column                        Non-Null Count   Dtype\n",
      "---  ------                        --------------   -----\n",
      " 0   patient_id                    100000 non-null  int64\n",
      " 1   date_ord                      100000 non-null  int64\n",
      " 2   heart_rate                    100000 non-null  int64\n",
      " 3   respiration_over_impedence    100000 non-null  int64\n",
      " 4   spirometry_oxygen_saturation  100000 non-null  int64\n",
      " 5   pulse                         100000 non-null  int64\n",
      " 6   blood_pressure_systolic       100000 non-null  int64\n",
      " 7   blood_pressure_diastolic      100000 non-null  int64\n",
      " 8   blood_pressure_average        100000 non-null  int64\n",
      "dtypes: int64(9)\n",
      "memory usage: 6.9 MB\n"
     ]
    }
   ],
   "source": [
    "X_train = trdf.iloc[:,0:9]\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count   Dtype\n",
      "---  ------  --------------   -----\n",
      " 0   Coded   100000 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 781.3 KB\n"
     ]
    }
   ],
   "source": [
    "y_train = trdf.iloc[:,9:10]\n",
    "y_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 351 entries, 0 to 350\n",
      "Data columns (total 9 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   patient_id                    351 non-null    int64  \n",
      " 1   date_ord                      351 non-null    int64  \n",
      " 2   heart_rate                    351 non-null    float64\n",
      " 3   respiration_over_impedence    351 non-null    float64\n",
      " 4   spirometry_oxygen_saturation  351 non-null    float64\n",
      " 5   pulse                         351 non-null    float64\n",
      " 6   blood_pressure_systolic       351 non-null    float64\n",
      " 7   blood_pressure_diastolic      351 non-null    float64\n",
      " 8   blood_pressure_average        351 non-null    float64\n",
      "dtypes: float64(7), int64(2)\n",
      "memory usage: 27.4 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "351"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = tdf.iloc[:,0:9]\n",
    "X_test.info()\n",
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 351 entries, 0 to 350\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Coded   351 non-null    float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 5.5 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "351"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = tdf.iloc[:,9:10]\n",
    "y_test.info()\n",
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = trdf.append(tdf)\n",
    "f_data = combined_data.iloc[:,0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_data = combined_data.iloc[:,9:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100351"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100351"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "First we will use the decision tress classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classifier creates a decision tree based on which, it assigns the class values to each data point. Here, we can vary the maximum number of features to be considered while creating the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 1.00\n",
      "Accuracy of Decision Tree classifier on test set: 0.59\n"
     ]
    }
   ],
   "source": [
    "#from sklearn import tree\n",
    "#clf = tree.DecisionTreeClassifier()\n",
    " \n",
    "dtc = DecisionTreeClassifier()\n",
    "fit = dtc.fit(X_train, y_train)\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(dtc.score(X_train, y_train)))\n",
    "print('Accuracy of Decision Tree classifier on test set: {:.2f}'\n",
    "     .format(dtc.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre = fit.predict(X_test) \n",
    "y_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[191 135]\n",
      " [ 10  15]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pre)\n",
    "print (cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.59      0.72       326\n",
      "         1.0       0.10      0.60      0.17        25\n",
      "\n",
      "    accuracy                           0.59       351\n",
      "   macro avg       0.53      0.59      0.45       351\n",
      "weighted avg       0.89      0.59      0.69       351\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test,y_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nithy_sku7r2v\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 20071  20072  20073 ... 100348 100349 100350] TEST: [    0     1     2 ... 20068 20069 20070]\n",
      "TRAIN: [     0      1      2 ... 100348 100349 100350] TEST: [20071 20072 20073 ... 40138 40139 40140]\n",
      "TRAIN: [     0      1      2 ... 100348 100349 100350] TEST: [40141 40142 40143 ... 60208 60209 60210]\n",
      "TRAIN: [     0      1      2 ... 100348 100349 100350] TEST: [60211 60212 60213 ... 80278 80279 80280]\n",
      "TRAIN: [    0     1     2 ... 80278 80279 80280] TEST: [ 80281  80282  80283 ... 100348 100349 100350]\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5,random_state=4)\n",
    "for train_index, test_index in kf.split(f_data):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train_1, X_test_1 = f_data.iloc[train_index], f_data.iloc[test_index]\n",
    "    y_train_1, y_test_1 = t_data.iloc[train_index], t_data.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold 0] score: 0.06686\n",
      "[fold 1] score: 0.65247\n",
      "[fold 2] score: 0.75117\n",
      "[fold 3] score: 0.48600\n",
      "[fold 4] score: 0.14489\n"
     ]
    }
   ],
   "source": [
    "for k, (train_index, test_index) in enumerate(kf.split(f_data)): \n",
    "    X_train_1, X_test_1 = f_data.iloc[train_index], f_data.iloc[test_index] \n",
    "    y_train_1, y_test_1 = t_data.iloc[train_index], t_data.iloc[test_index] \n",
    "    clf.fit(X_train_1, y_train_1) \n",
    "    print (\"[fold {0}] score: {1:.5f}\".format(k, clf.score(X_test_1, y_test_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_feature_names = list(f_data.columns)\n",
    "training_target_names_object = training_df['Coded'].apply(lambda x: \"C\" if x == 1 else \"NC\").unique()\n",
    "training_target_names = list(training_target_names_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_1 = DecisionTreeClassifier(criterion='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_1 = clf_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre_1 = fit_1.predict(X_test)   \n",
    "y_pre_1\n",
    "y_pre_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[191 135]\n",
      " [ 10  15]]\n"
     ]
    }
   ],
   "source": [
    "cm_1 = confusion_matrix(y_test, y_pre_1)\n",
    "print (cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.87      0.90       326\n",
      "         1.0       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.81       351\n",
      "   macro avg       0.46      0.44      0.45       351\n",
      "weighted avg       0.85      0.81      0.83       351\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test,y_pre_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold 0] score: 0.05555\n",
      "[fold 1] score: 0.64011\n",
      "[fold 2] score: 0.75790\n",
      "[fold 3] score: 0.48445\n",
      "[fold 4] score: 0.17070\n"
     ]
    }
   ],
   "source": [
    "for k, (train_index, test_index) in enumerate(kf.split(f_data)): \n",
    "    X_train_1, X_test_1 = f_data.iloc[train_index], f_data.iloc[test_index] \n",
    "    y_train_1, y_test_1 = t_data.iloc[train_index], t_data.iloc[test_index] \n",
    "    clf_1.fit(X_train_1, y_train_1) \n",
    "    print (\"[fold {0}] score: {1:.5f}\".format(k, clf_1.score(X_test_1, y_test_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k nearest neighbours algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classifier looks for the classes of K nearest neighbors of a given data point and based on the majority class, it assigns a class to this data point. However, the number of neighbors can be varied. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(f_data, t_data, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60210, 9)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60210, 1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40141, 9)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40141, 1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train/test split] score: 0.82915\n"
     ]
    }
   ],
   "source": [
    "print (\"[Train/test split] score: {:.5f}\".format(clf.score(X_test1, y_test1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-46-bdec0f7c2924>:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  clf.fit(X_train1, y_train1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "k = 1\n",
      "Confusion matrix:\n",
      " [[27249   878]\n",
      " [  515 11499]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.97      0.98     28127\n",
      "         1.0       0.93      0.96      0.94     12014\n",
      "\n",
      "    accuracy                           0.97     40141\n",
      "   macro avg       0.96      0.96      0.96     40141\n",
      "weighted avg       0.97      0.97      0.97     40141\n",
      "\n",
      "\n",
      "Accuracy for kNN : 96.530%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-46-bdec0f7c2924>:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  clf.fit(X_train1, y_train1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "k = 2\n",
      "Confusion matrix:\n",
      " [[27558   569]\n",
      " [ 1061 10953]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.98      0.97     28127\n",
      "         1.0       0.95      0.91      0.93     12014\n",
      "\n",
      "    accuracy                           0.96     40141\n",
      "   macro avg       0.96      0.95      0.95     40141\n",
      "weighted avg       0.96      0.96      0.96     40141\n",
      "\n",
      "\n",
      "Accuracy for kNN : 95.939%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-46-bdec0f7c2924>:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  clf.fit(X_train1, y_train1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "k = 3\n",
      "Confusion matrix:\n",
      " [[27075  1052]\n",
      " [  650 11364]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.96      0.97     28127\n",
      "         1.0       0.92      0.95      0.93     12014\n",
      "\n",
      "    accuracy                           0.96     40141\n",
      "   macro avg       0.95      0.95      0.95     40141\n",
      "weighted avg       0.96      0.96      0.96     40141\n",
      "\n",
      "\n",
      "Accuracy for kNN : 95.760%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-46-bdec0f7c2924>:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  clf.fit(X_train1, y_train1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "k = 4\n",
      "Confusion matrix:\n",
      " [[27361   766]\n",
      " [ 1071 10943]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.97      0.97     28127\n",
      "         1.0       0.93      0.91      0.92     12014\n",
      "\n",
      "    accuracy                           0.95     40141\n",
      "   macro avg       0.95      0.94      0.95     40141\n",
      "weighted avg       0.95      0.95      0.95     40141\n",
      "\n",
      "\n",
      "Accuracy for kNN : 95.424%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-46-bdec0f7c2924>:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  clf.fit(X_train1, y_train1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "k = 5\n",
      "Confusion matrix:\n",
      " [[26975  1152]\n",
      " [  822 11192]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.96      0.96     28127\n",
      "         1.0       0.91      0.93      0.92     12014\n",
      "\n",
      "    accuracy                           0.95     40141\n",
      "   macro avg       0.94      0.95      0.94     40141\n",
      "weighted avg       0.95      0.95      0.95     40141\n",
      "\n",
      "\n",
      "Accuracy for kNN : 95.082%\n"
     ]
    }
   ],
   "source": [
    "for x in range(1,6):\n",
    "    clf = KNeighborsClassifier(x)\n",
    "    clf.fit(X_train1, y_train1)\n",
    "    predicted = clf.predict(X_test1)\n",
    "    accuracy = metrics.accuracy_score(predicted,y_test1)\n",
    "    cm = confusion_matrix(y_test1,predicted)\n",
    "    print (\"\\nk = \"+ str(x))\n",
    "    print (\"Confusion matrix:\\n\", cm)\n",
    "    print (classification_report(y_test1, predicted)+\"\\n\")\n",
    "    print(\"Accuracy for kNN : %s\" % \"{0:.3%}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that for k=4, the accuracy and the precision is highest. Let us check the results with cross fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-47-adcf42d2f716>:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  clf.fit(X_train1, y_train1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(40141,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "clf = KNeighborsClassifier(4)\n",
    "clf.fit(X_train1, y_train1)\n",
    "predicted = clf.predict(X_test1)\n",
    "predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-48-0881bcc79274>:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  clf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold 0] score: 0.97808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-48-0881bcc79274>:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  clf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold 1] score: 0.99417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-48-0881bcc79274>:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  clf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold 2] score: 0.99402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-48-0881bcc79274>:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  clf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold 3] score: 0.96442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-48-0881bcc79274>:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  clf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold 4] score: 0.96487\n"
     ]
    }
   ],
   "source": [
    "for k, (train_index, test_index) in enumerate(kf.split(f_data)): \n",
    "    X_train_1, X_test_1 = f_data.iloc[train_index], f_data.iloc[test_index] \n",
    "    y_train_1, y_test_1 = t_data.iloc[train_index], t_data.iloc[test_index] \n",
    "    clf.fit(X_train, y_train) \n",
    "    print (\"[fold {0}] score: {1:.5f}\".format(k, clf.score(X_test_1, y_test_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nithy_sku7r2v\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(f_data, t_data, test_size=0.4, random_state=0)\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train2, y_train2)\n",
    "prediction_nb = clf.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40141,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_nb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25648  2479]\n",
      " [ 9128  2886]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test2,prediction_nb)\n",
    "print (cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.91      0.82     28127\n",
      "         1.0       0.54      0.24      0.33     12014\n",
      "\n",
      "    accuracy                           0.71     40141\n",
      "   macro avg       0.64      0.58      0.57     40141\n",
      "weighted avg       0.68      0.71      0.67     40141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test2, prediction_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Naive Bayes : 71.084%\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(prediction_nb,y_test2)\n",
    "print(\"Accuracy for Naive Bayes : %s\" % \"{0:.3%}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nithy_sku7r2v\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold 0] score: 0.85252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nithy_sku7r2v\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold 1] score: 0.83832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nithy_sku7r2v\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold 2] score: 0.98724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nithy_sku7r2v\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold 3] score: 0.49123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nithy_sku7r2v\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold 4] score: 0.12466\n"
     ]
    }
   ],
   "source": [
    "for k, (train_index, test_index) in enumerate(kf.split(f_data)): \n",
    "    X_train_1, X_test_1 = f_data.iloc[train_index], f_data.iloc[test_index] \n",
    "    y_train_1, y_test_1 = t_data.iloc[train_index], t_data.iloc[test_index] \n",
    "    clf.fit(X_train_1, y_train_1) \n",
    "    print (\"[fold {0}] score: {1:.5f}\".format(k, clf.score(X_test_1, y_test_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Accuracy of KNN<b/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for kNN : 95.424%\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(predicted,y_test1)\n",
    "print(\"Accuracy for kNN : %s\" % \"{0:.3%}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Accuracy of Decission Trees- Gini & Entropy</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Decision Tree : 58.689%\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(y_pre,y_test)\n",
    "print(\"Accuracy for Decision Tree : %s\" % \"{0:.3%}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Decision Tree : 81.197%\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(y_pre_1,y_test)\n",
    "print(\"Accuracy for Decision Tree : %s\" % \"{0:.3%}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Accuracy of Naive Bayes</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Naive Bayes : 71.084%\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(prediction_nb,y_test2)\n",
    "print(\"Accuracy for Naive Bayes : %s\" % \"{0:.3%}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "After analysis predictive models Naive Bayes, KNN and Decision tree for this give data, the accuracy of the <b>K nearest neighbours algorithm is best btoh because of its accuracy and the K fold Validation.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of the K nearest neighbours algorithm is  <b>95.424%</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model can then be used as a simple predicting tool and all that we need to do is to input ones: pulse,systolic and diastolic blood pressures, heart rate and blood glucose levels after which the model can be run and it outputs a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
